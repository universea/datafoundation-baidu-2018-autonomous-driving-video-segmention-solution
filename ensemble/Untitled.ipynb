{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "H:\\ObjectDetection\\AiRobot_WAD_Video_Segmentation\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import multiprocessing\n",
    "from functools import partial\n",
    "\n",
    "from pathlib import Path\n",
    "import skimage.io\n",
    "import scipy.ndimage as ndimage\n",
    "import sys, os\n",
    "\n",
    "# 获取项目根目录\n",
    "ROOT_DIR = os.path.abspath(\"../\")\n",
    "sys.path.append(ROOT_DIR)\n",
    "print (ROOT_DIR)\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"maskrcnn/\"))\n",
    "sys.path.append(os.path.join(ROOT_DIR, \"maskrcnn/mrcnn/\"))\n",
    "from adriving_util import *\n",
    "from visualize import *\n",
    "import skimage.morphology\n",
    "import skimage.transform\n",
    "from tqdm import tqdm\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from unionfind import UnionFind\n",
    "\n",
    "import json\n",
    "\n",
    "#基础配置路径\n",
    "settingsDir = os.path.join(ROOT_DIR,'settings.json')\n",
    "print (settingsDir)\n",
    "with open(settingsDir) as f:\n",
    "    setting = json.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SC_TH = 0.5\n",
    "PX_TH = 50\n",
    "prediction_folder_list = []\n",
    "output_folder = 'dummy'\n",
    "\n",
    "def compute_iou_masks_partial_bck(masks1, mask2):\n",
    "    '''Computes IoU overlaps between two sets of masks.\n",
    "    masks1, masks2: [Height, Width]\n",
    "    '''\n",
    "    # flatten masks\n",
    "    masks1 = np.reshape(masks1, (-1, masks1.shape[-1])).astype(bool)\n",
    "    mask2 = np.reshape(mask2, -1).astype(bool)\n",
    "\n",
    "    area1 = np.sum(masks1, axis = 0) + 1e-3\n",
    "    area2 = np.repeat(np.sum(mask2), masks1.shape[-1])\n",
    "    # return area1, area2\n",
    "\n",
    "    # intersections and union\n",
    "    intersections = np.dot(masks1.T, mask2)\n",
    "    union = area1 + area2 - intersections\n",
    "    overlaps = intersections / area1\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "def compute_iou_masks_partial(masks1, mask2):\n",
    "    '''Computes IoU overlaps between two sets of masks.\n",
    "    masks1, masks2: [Height, Width]\n",
    "    '''\n",
    "    # flatten masks\n",
    "    # mask2 = np.repeat(mask2[:, :, np.newaxis], masks1.shape[2], axis=2)\n",
    "    area1 = np.sum(masks1, axis = (0,1)) + 1e-3\n",
    "    area2 = np.array([np.sum(mask2)] * masks1.shape[2])\n",
    "    # return area1, area2\n",
    "\n",
    "    # intersections and union\n",
    "    intersections = []\n",
    "    for i in range(masks1.shape[2]):\n",
    "        intersections.append(np.sum(masks1[:, :, i] * mask2))\n",
    "    intersections = np.array(intersections)\n",
    "    # print(intersections)\n",
    "    union = area1 + area2 - intersections\n",
    "    overlaps = intersections / area1\n",
    "\n",
    "    return overlaps\n",
    "\n",
    "def compute_iou_masksets_partial(masks1, masks2):\n",
    "    results = np.zeros([masks1.shape[-1], masks2.shape[-1]])\n",
    "    for n in range(masks2.shape[-1]):\n",
    "        # print(n)\n",
    "        results[:, n] = compute_iou_masks_partial(masks1, masks2[:, :, n])\n",
    "    return results\n",
    "\n",
    "import scipy.ndimage.measurements\n",
    "def remove_disconnected_instance(mask_this):\n",
    "    mask_label, num_features = scipy.ndimage.measurements.label(mask_this)\n",
    "    n_pixels = []\n",
    "    if num_features <= 1:\n",
    "        return mask_this\n",
    "\n",
    "    for n in range(np.max(mask_label)):\n",
    "        n_pixels.append(np.sum(mask_label==n))\n",
    "    n_pixels = np.array(n_pixels)\n",
    "\n",
    "    index = np.argmax(n_pixels)\n",
    "\n",
    "    return (mask_label == n)\n",
    "\n",
    "def remove_disconnected(mask_instance):\n",
    "    mask_remove = np.zeros(mask_instance.shape, dtype = bool)\n",
    "    for n in range(mask_instance.shape[2]):\n",
    "        mask_remove[:, :, n] = remove_disconnected_instance(mask_instance[:, :, n])\n",
    "    return mask_remove\n",
    "\n",
    "def remove_duplicates_instance_to_mask(mask, class_ids, score, PX_TH = 20, SC_TH = 0.3):\n",
    "    \n",
    "    mask_resize = mask[::5, ::5, :]\n",
    "    iou_matrix = compute_iou_masksets_partial(mask_resize, mask_resize)\n",
    "\n",
    "    uf = UnionFind(list(range(mask.shape[2])))\n",
    "    overlap = list()\n",
    "    for i in range(mask.shape[2]):\n",
    "        for j in range(mask.shape[2]):\n",
    "            if i == j:\n",
    "                continue\n",
    "            else:\n",
    "                if iou_matrix[i, j] > 0.8 and class_ids[i] == class_ids[j]:\n",
    "                    uf.union(i, j)\n",
    "                    overlap.append(i)\n",
    "                    overlap.append(j)\n",
    "\n",
    "    overlap = np.unique(overlap)\n",
    "\n",
    "    keep = []\n",
    "    for n in range(iou_matrix.shape[0]):\n",
    "        if n not in overlap:\n",
    "            keep.append(n)\n",
    "    # print('keep', keep)\n",
    "\n",
    "    mask_instance_new = mask[:, :, keep]\n",
    "    class_ids_new = list(class_ids[keep])\n",
    "    score_new = list(score[keep])\n",
    "\n",
    "    merged_sets = []\n",
    "    for n, pair in enumerate(uf.components()):\n",
    "        if len(pair) >= 2:\n",
    "            merged_sets.append(pair)\n",
    "\n",
    "\n",
    "    mask_instance_merged = np.zeros([mask.shape[0],\n",
    "                                     mask.shape[1], len(merged_sets)],\n",
    "                                    dtype = bool)\n",
    "\n",
    "    for n, pair in enumerate(merged_sets):\n",
    "        mask_instance_merged[:, :, n] = np.zeros([mask.shape[0],\n",
    "                                     mask.shape[1]],\n",
    "                                    dtype = bool)\n",
    "        scores_this_set = []\n",
    "        index_this_set = []\n",
    "        class_id_this_set = []\n",
    "        px_num_this_set = []\n",
    "        for p in pair:\n",
    "            scores_this_set.append(score[p])\n",
    "            index_this_set.append(p)\n",
    "            class_id_this_set.append(class_ids[p])\n",
    "            px_num_this_set.append(np.sum(mask[:, :, p], axis = (0, 1)))\n",
    "            \n",
    "        index = np.argmax(np.array(scores_this_set))\n",
    "        mask_instance_merged[:, :, n] = mask[:, :, index_this_set[index]]\n",
    "\n",
    "        class_ids_new.append(class_id_this_set[index])\n",
    "        score_new.append(scores_this_set[index])\n",
    "\n",
    "    # print('before', mask_instance_new.shape)\n",
    "    mask_instance_new = np.dstack((mask_instance_new, mask_instance_merged))\n",
    "    # mask_instance_new = mask_instance_merged\n",
    "    class_ids_pred = np.array(class_ids_new)\n",
    "    scores_pred = np.array(score_new)\n",
    "\n",
    "    # print('after', mask_instance_new.shape)\n",
    "\n",
    "    n_px_per_instance = np.sum(mask_instance_new, axis = (0, 1))\n",
    "    instance_keep = np.where(np.logical_and((n_px_per_instance > PX_TH) , (scores_pred > SC_TH)))[0]\n",
    "    if len(instance_keep) == 0:\n",
    "        return None, None\n",
    "    # print(instance_keep)\n",
    "    instance_reorder = instance_keep[np.argsort(scores_pred[instance_keep])]\n",
    "    # print(instance_reorder)\n",
    "    score_reorder = scores_pred[instance_reorder]\n",
    "    class_ids_reorder = class_ids_pred[instance_reorder]\n",
    "    mask_reorder = mask_instance_new[:, :, instance_reorder]\n",
    "    mask_reorder = remove_disconnected(mask_reorder)\n",
    "    # print(mask_reorder.shape)\n",
    "    # mask_reorder = fill_and_remove(mask_reorder)\n",
    "    mask, instance_score = instance_to_mask(mask_reorder, class_ids_reorder,\n",
    "                                                  score_reorder,\n",
    "                                                  order_by_score = False)\n",
    "\n",
    "    return mask, instance_score\n",
    "\n",
    "\n",
    "import skimage.morphology\n",
    "\n",
    "def fill_and_remove(mask_instance):\n",
    "    selem = skimage.morphology.disk(3)\n",
    "    mask_instance_filled = mask_instance.copy()\n",
    "    for n in range(mask_instance.shape[2]):\n",
    "        n_pixels = np.sum(mask_instance[:, :, n])\n",
    "        if n_pixels > 5000:\n",
    "            selem = skimage.morphology.disk(3)\n",
    "        else:\n",
    "            selem = skimage.morphology.disk(1)\n",
    "\n",
    "    return mask_instance_filled\n",
    "\n",
    "def get_prediction_from_csv(prediction, image_id):\n",
    "    prediction_this_image = prediction.loc[prediction['ImageId'] == image_id]\n",
    "    num_instances = len(prediction_this_image)\n",
    "    mask_pred_list = list()\n",
    "    # mask_pred = np.zeros([2710, 3384, num_instances], dtype = bool)\n",
    "    class_ids_pred = np.zeros(num_instances, dtype = int)\n",
    "    score_ids_pred = np.zeros(num_instances, dtype = float)\n",
    "    for n in range(num_instances):\n",
    "        rle = prediction_this_image.iloc[n]['EncodedPixels']\n",
    "        mask_pred_list.append(rle_decode(rle, (2710, 3384)).astype(bool))\n",
    "        # assert(np.sum(mask_pred[:,:, n]) == int(prediction_this_image.iloc[n]['PixelCount']))\n",
    "        class_ids_pred[n] = label_to_class[int(prediction_this_image.iloc[n]['LabelId'])]\n",
    "        score_ids_pred[n] = float(prediction_this_image.iloc[n]['Confidence'])\n",
    "    return mask_pred_list, class_ids_pred, score_ids_pred\n",
    "\n",
    "def get_prediction_and_csv(prediction_folder_list, image_id):\n",
    "    class_ids_pred_list = []\n",
    "    scores_pred_list = []\n",
    "    mask_pred_list = []\n",
    "    for prediction_folder in prediction_folder_list:\n",
    "        if os.path.isdir(prediction_folder):\n",
    "            if not os.path.isfile(prediction_folder + '/'+ image_id + '.p'):\n",
    "                continue\n",
    "            with open(prediction_folder + '/'+ image_id + '.p', 'rb') as f:\n",
    "\n",
    "                prediction = pickle.load(f)\n",
    "                #print(prediction)\n",
    "                class_ids_pred = prediction['class_ids']\n",
    "                class_ids_pred_list += class_ids_pred.tolist()\n",
    "                scores_pred = prediction['scores']\n",
    "                scores_pred_list += scores_pred.tolist()\n",
    "\n",
    "                for n in range(len(class_ids_pred)):\n",
    "                    mask_pred = np.zeros([2710, 3384], dtype = bool)\n",
    "                    h, w = prediction['masks'][0].toarray().shape\n",
    "                    if h == 2048:\n",
    "                        mask_pred[-2048:, :] = prediction['masks'][n].toarray()[:, 100:(100+3384)]\n",
    "                    else:\n",
    "                        mask_recover = prediction['masks'][n].toarray()\n",
    "                        mask_recover =  skimage.transform.resize(\n",
    "                                mask_recover, (2*h, 2*w),\n",
    "                                order=0, mode=\"constant\", preserve_range=True)\n",
    "                        mask_pred[-2048:, :] = mask_recover[:, 100:(100+3384)]\n",
    "                    mask_pred_list.append(mask_pred.astype(bool))\n",
    "        else:\n",
    "            prediction_file = pd.read_csv(prediction_folder)\n",
    "            image_list = list(np.unique(prediction_file.ImageId))\n",
    "            if image_id not in (image_list):\n",
    "                continue\n",
    "            mask_pred, class_ids_pred, scores_pred = get_prediction_from_csv(prediction_file, image_id)\n",
    "            class_ids_pred_list += class_ids_pred.tolist()\n",
    "            scores_pred_list += scores_pred.tolist()\n",
    "            mask_pred_list += mask_pred\n",
    "\n",
    "    return np.stack(mask_pred_list, axis = -1), np.array(class_ids_pred_list), np.array(scores_pred_list)\n",
    "\n",
    "\n",
    "def read_and_rle(image_id, prediction_folder_list=prediction_folder_list,\n",
    "                output_folder=output_folder, SC_TH = 0.3, PX_TH = 20):\n",
    "    mask_pred, class_ids_pred, scores_pred = get_prediction_and_csv(prediction_folder_list, image_id)\n",
    "    # pipeline:\n",
    "    n_px_per_instance = np.sum(mask_pred, axis = (0, 1))\n",
    "    instance_keep = np.where(np.logical_and((n_px_per_instance > PX_TH) , (scores_pred > SC_TH)))[0]\n",
    "    # print(instance_keep)\n",
    "    if len(instance_keep) == 0:\n",
    "        return 0\n",
    "\n",
    "    instance_reorder = instance_keep[np.argsort(scores_pred[instance_keep])]\n",
    "\n",
    "    score_reorder = scores_pred[instance_reorder]\n",
    "    class_ids_reorder = class_ids_pred[instance_reorder]\n",
    "    mask_reorder = mask_pred[:, :, instance_reorder]\n",
    "\n",
    "    # mask_reorder = fill_and_remove(mask_reorder)\n",
    "    # print(class_ids_reorder)\n",
    "    mask, instance_score = remove_duplicates_instance_to_mask(mask_reorder, class_ids_reorder,\n",
    "                                                                score_reorder,\n",
    "                                                                SC_TH = SC_TH, PX_TH = PX_TH)\n",
    "\n",
    "    # pipeline_end\n",
    "    if mask is not None:\n",
    "        rle_string_list = write_mask(image_id, mask, score = instance_score)\n",
    "        fileoutput_name = output_folder + '/'+ image_id + '.csv'\n",
    "        with open(fileoutput_name, 'w+') as prediction_file:\n",
    "            for rle_str in rle_string_list:\n",
    "                prediction_file.write(rle_str)\n",
    "                prediction_file.write('\\n')\n",
    "        return 0\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == '__main__':\n",
    "    import argparse\n",
    "\n",
    "    # Parse command line arguments\n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='Train Mask R-CNN on MS COCO.')\n",
    "\n",
    "    parser.add_argument('--px_th', required=False,\n",
    "                        default=50,\n",
    "                        metavar=\"<px>\",\n",
    "                        help='px')\n",
    "    parser.add_argument('--sc_th', required=False,\n",
    "                        default=0.1,\n",
    "                        metavar=\"<sc>\",\n",
    "                        help='px')\n",
    "\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    PX_TH = int(args.px_th)\n",
    "    SC_TH = float(args.sc_th)\n",
    "\n",
    "    # prediction_folder_list = ['test_resnet_v2_201806010_00_mask_th_0.5_nms_th_0.8_Scale_1_Flip_False_DT_NMS_TH_0.3', \n",
    "    #                           'test_20180521_00_mask_th0.35_nms_th_0.6_Scale_1Flip_False',\n",
    "    #                           'test_20180521_00_mask_th0.35_nms_th_0.6_Scale_1Flip_True',\n",
    "    #                           'test_20180506_01_px_30sc_0.5.csvpx20_th0.5.csv' ]\n",
    "    prediction_folder_list = os.listdir(os.path.join('../../', setting['SUBMISSION_DIR'], 'ensemble'))\n",
    "    prediction_folder_list = [x for x in prediction_folder_list if not x.startswith('.')]\n",
    "    prediction_folder_list = [os.path.join('../../', setting['SUBMISSION_DIR'], 'ensemble', x) for x in prediction_folder_list]\n",
    "    print(prediction_folder_list)\n",
    "    # output_folder = ''\n",
    "    # for prediction_folder in prediction_folder_list:\n",
    "    #     output_folder += prediction_folder + '_'\n",
    "    # output_folder = output_folder + '_px_{}sc_{}_ensemble_keep'.format(PX_TH, SC_TH)\n",
    "    output_folder = 'final_prediction' + '_px_{}sc_{}'.format(PX_TH, SC_TH)\n",
    "    output_folder = os.path.join('../../', setting['SUBMISSION_DIR'], output_folder)\n",
    "\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "    # output_folder = prediction_folder + '_px_{}sc_{}'.format(PX_TH, SC_TH)\n",
    "    image_list = []\n",
    "    for prediction_folder in prediction_folder_list:\n",
    "        if os.path.isdir(prediction_folder):\n",
    "\n",
    "            image_list_this = os.listdir(prediction_folder)\n",
    "            image_list_this = [x[:-2] for x in image_list_this if x[0] != '.']\n",
    "        else:\n",
    "            prediction_file = pd.read_csv(prediction_folder)\n",
    "            image_list_this = list(np.unique(prediction_file.ImageId))\n",
    "        image_list += image_list_this\n",
    "    image_list = list(set(image_list))\n",
    "    image_list = sorted(image_list)\n",
    "    print(len(image_list))\n",
    "    # image_list = image_list[195:]\n",
    "\n",
    "    n_core = min(multiprocessing.cpu_count(), 4)\n",
    "\n",
    "    with multiprocessing.Pool(n_core) as p:\n",
    "        r = list(tqdm(p.imap(partial(read_and_rle,\n",
    "                            prediction_folder_list=prediction_folder_list,\n",
    "                            output_folder=output_folder,\n",
    "                            SC_TH = SC_TH, PX_TH = PX_TH),\n",
    "                            image_list),\n",
    "                            total=len(image_list)))\n",
    "\n",
    "    output_file = output_folder + '.csv'\n",
    "\n",
    "    filenames = os.listdir(output_folder)\n",
    "    filenames = [x for x in filenames if x[0] != '.']\n",
    "    filenames = sorted(filenames)\n",
    "    filenames = [os.path.join(output_folder, x) for x in filenames]\n",
    "    outfile_list = []\n",
    "\n",
    "    for fname in filenames:\n",
    "        with open(fname) as infile:\n",
    "            for line in infile:\n",
    "                line = line[:-1]\n",
    "                outfile_list.append(line.split(','))\n",
    "\n",
    "    out_file = pd.DataFrame(outfile_list, columns = ['ImageId','LabelId','Confidence','PixelCount','EncodedPixels'])\n",
    "    out_file['PixelCount'] = (out_file['PixelCount']).astype(int)\n",
    "    out_file['LabelId'] = (out_file['LabelId']).astype(int)\n",
    "    out_file['Confidence'] = (out_file['Confidence']).astype(float)\n",
    "    out_file = out_file.loc[out_file.PixelCount > PX_TH]\n",
    "    out_file = out_file.sort_values(['ImageId', 'Confidence'], ascending=[True, False])\n",
    "    out_file.to_csv(output_file, index = False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
